{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from models import naive_bayes, logistic, random_forest, k_cross_val\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "data = pd.read_csv('data/clean_data.csv',index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results from the initial model fitting, it seems as though the numerical features we collected using Tweepy were not particularly useful. This could be because the features themselves are not informative or because the imputation techniques we used for the missing tweets were not good. If we have time, we can go back and try more advanced imputation techniques. For now, let's ignore the imputed numerical features except for date_time. Date_time should be reliable because tweets are organized chronologically by tweet id and so the missing date_times we imputed should be fairly reliable. Let's also keep numerical features that we collected directly from the text like exclamation_mark_count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean text</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>is_quoted</th>\n",
       "      <th>date_time</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>followers</th>\n",
       "      <th>verified</th>\n",
       "      <th>location</th>\n",
       "      <th>exclamation_mark_count</th>\n",
       "      <th>question_mark_count</th>\n",
       "      <th>imputed</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaaaaand delet glob warm rain tweet cas miss s...</td>\n",
       "      <td>794050846807982080</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-11-03 05:37:29</td>\n",
       "      <td>47</td>\n",
       "      <td>79</td>\n",
       "      <td>20106</td>\n",
       "      <td>1</td>\n",
       "      <td>NYC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean text             tweetid  \\\n",
       "2  aaaaaand delet glob warm rain tweet cas miss s...  794050846807982080   \n",
       "\n",
       "   is_retweet  is_quoted           date_time  retweets  favorites  followers  \\\n",
       "2           1          0 2016-11-03 05:37:29        47         79      20106   \n",
       "\n",
       "   verified location  exclamation_mark_count  question_mark_count  imputed  \\\n",
       "2         1      NYC                       0                    0    False   \n",
       "\n",
       "   sentiment  month  hour  dayofweek  \n",
       "2         -1     11     5          3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding date time features\n",
    "data['date_time'] = pd.to_datetime(data['date_time'])\n",
    "data['month'] = data['date_time'].dt.month\n",
    "data['hour'] = data['date_time'].dt.hour\n",
    "data['dayofweek'] = data['date_time'].dt.dayofweek\n",
    "data.iloc[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial class distribution\n",
      "class 1:  0.6481264232972189\n",
      "class 0:  0.22859015940928853\n",
      "class -1:  0.12328341729349251\n",
      "Upsampled class distribution\n",
      "class 1:  0.3333333333333333\n",
      "class 0:  0.3333333333333333\n",
      "class -1:  0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "# upsampling seemed to improve results so let's continue doing this\n",
    "\n",
    "n = len(data)\n",
    "print('Initial class distribution')\n",
    "print('class 1: ', len(data[data['sentiment']==1])/n)\n",
    "print('class 0: ', len(data[data['sentiment']==0])/n)\n",
    "print('class -1: ', len(data[data['sentiment']==-1])/n)\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "diffneg = (len(data[data['sentiment']==1]) - \n",
    "        len(data[data['sentiment']==-1])) # want to creat 33-33-33 balance\n",
    "diffneu = (len(data[data['sentiment']==1]) - \n",
    "        len(data[data['sentiment']==0])) # want to creat 33-33-33 balance\n",
    "\n",
    "neg_data = data[data['sentiment']==-1] # sample to choose from\n",
    "neu_data = data[data['sentiment']==0] # sample to choose from\n",
    "\n",
    "upsample_index_neg = np.random.choice(neg_data.index,size=diffneg) # sample with repetition\n",
    "upsample_index_neu = np.random.choice(neu_data.index,size=diffneu) # sample with repetition\n",
    "\n",
    "data_ups = data.append(neg_data.loc[upsample_index_neg]).append(neu_data.loc[upsample_index_neu]).sample(frac=1)\n",
    "\n",
    "n = len(data_ups)\n",
    "print('Upsampled class distribution')\n",
    "print('class 1: ', len(data_ups[data_ups['sentiment']==1])/n)\n",
    "print('class 0: ', len(data_ups[data_ups['sentiment']==0])/n)\n",
    "print('class -1: ', len(data_ups[data_ups['sentiment']==-1])/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into testing and training sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(data_ups.drop(labels = \"sentiment\", axis = 1), \n",
    "                                                    data_ups[\"sentiment\"], test_size=0.2, \n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select just the numerical data\n",
    "numerical_feature_names = ['exclamation_mark_count', 'question_mark_count','month','hour','dayofweek']\n",
    "X_train_numerical = X_train.loc[:,numerical_feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.feature_extraction.text.CountVectorizer'>\n",
      "n-gram:  (1, 1)\n",
      "Accuracy:  0.8962756265671498\n",
      "Precision:  0.8971316026935282\n",
      "Recall:  0.8963747930448666\n",
      "F score:  0.8952602867572047\n",
      "n-gram:  (1, 2)\n",
      "Accuracy:  0.8921496923045584\n",
      "Precision:  0.89496521274199\n",
      "Recall:  0.8922580278359604\n",
      "F score:  0.8911518410132888\n",
      "n-gram:  (1, 3)\n",
      "Accuracy:  0.8909296981084432\n",
      "Precision:  0.8945634687950432\n",
      "Recall:  0.891035682712479\n",
      "F score:  0.8899493985250444\n",
      "n-gram:  (2, 2)\n",
      "Accuracy:  0.8900424038828756\n",
      "Precision:  0.8918710181642598\n",
      "Recall:  0.8901701293288931\n",
      "F score:  0.8897688771811273\n",
      "n-gram:  (2, 3)\n",
      "Accuracy:  0.8864266983029886\n",
      "Precision:  0.8883014053458954\n",
      "Recall:  0.8865457950462232\n",
      "F score:  0.8858787897968792\n",
      "n-gram:  (3, 3)\n",
      "Accuracy:  0.8554601561538252\n",
      "Precision:  0.8624233906219041\n",
      "Recall:  0.8556111031621623\n",
      "F score:  0.8528549248367756\n",
      "<class 'sklearn.feature_extraction.text.TfidfVectorizer'>\n",
      "n-gram:  (1, 1)\n",
      "Accuracy:  0.9022648853457224\n",
      "Precision:  0.9021834624408583\n",
      "Recall:  0.9023819409498209\n",
      "F score:  0.901568657069253\n",
      "n-gram:  (1, 2)\n",
      "Accuracy:  0.8868259761532957\n",
      "Precision:  0.8907798232489604\n",
      "Recall:  0.8869554893074284\n",
      "F score:  0.885568158192803\n",
      "n-gram:  (1, 3)\n",
      "Accuracy:  0.8625806829040954\n",
      "Precision:  0.8756078211674257\n",
      "Recall:  0.8627440002345343\n",
      "F score:  0.8594468980462784\n",
      "n-gram:  (2, 2)\n",
      "Accuracy:  0.8415962641403268\n",
      "Precision:  0.8612869476301219\n",
      "Recall:  0.8417924553797971\n",
      "F score:  0.8370130968946821\n",
      "n-gram:  (2, 3)\n",
      "Accuracy:  0.8167077192946891\n",
      "Precision:  0.8487122153493386\n",
      "Recall:  0.8169246595241126\n",
      "F score:  0.8072335881831705\n",
      "n-gram:  (3, 3)\n",
      "Accuracy:  0.8458552754390087\n",
      "Precision:  0.8538941374681341\n",
      "Recall:  0.8460664414031621\n",
      "F score:  0.8420764979400426\n"
     ]
    }
   ],
   "source": [
    "# compare 5 fold cross validation error metrics for count and tfidf vectorizer with\n",
    "# 1, 2, 3-grams\n",
    "\n",
    "for skvectorizeri in [CountVectorizer,TfidfVectorizer]:\n",
    "    print(skvectorizeri)\n",
    "    for ngrami in [(1,1),(1,2),(1,3),(2,2),(2,3),(3,3)]:\n",
    "        rf = random_forest(X_train[\"clean text\"].values, y_train.values, X_train_numerical.values,\n",
    "                           ngram=ngrami,skvectorizer=skvectorizeri)\n",
    "        print('n-gram: ',ngrami)\n",
    "        print('Accuracy: ',rf[0])\n",
    "        print('Precision: ',rf[1])\n",
    "        print('Recall: ',rf[2])\n",
    "        print('F score: ',rf[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFIDF vectorizer with 1-grams had the best performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forests perform implicit feature selection by splitting on the most important nodes, but it can still be useful to look at which features it deemed the most important if we want to speed up the model (especially if performing hyperparameter optimization) and potentially use as feature selection for other models. Two things to note:\n",
    "- random forests are biased towards features with high cardinality (more categories)\n",
    "- if there are correlated features, one of them will cary most of the importance because once a node splits on a feature the other correlated features will not offer much new information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 402.688111782074\n",
      "(0.9011557829394325, 0.9014004984030946, 0.9012790371225587, 0.9004411015154868)\n"
     ]
    }
   ],
   "source": [
    "# create feature matrix\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,1))\n",
    "features = vectorizer.fit_transform(X_train[\"clean text\"].values)\n",
    "features = hstack([features, csr_matrix(X_train_numerical.values)])\n",
    "\n",
    "# 5 fold cross validation on training data\n",
    "start = time.time()\n",
    "rf_classifier = RandomForestClassifier()\n",
    "errors = k_cross_val(rf_classifier,features.tocsr(),y_train.values,k=5)\n",
    "stop = time.time()\n",
    "\n",
    "print('time:',stop-start)\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature: chang  |  0.02229\n",
      "feature: clim  |  0.02086\n",
      "feature: hour  |  0.01712\n",
      "feature: month  |  0.01483\n",
      "feature: warm  |  0.01455\n",
      "feature: glob  |  0.01443\n",
      "feature: dayofweek  |  0.01363\n",
      "feature: deny  |  0.0077\n",
      "feature: lib  |  0.00732\n",
      "feature: sci  |  0.00615\n",
      "feature: scam  |  0.00599\n",
      "feature: obam  |  0.00532\n",
      "feature: real  |  0.00496\n",
      "feature: trump  |  0.00488\n",
      "feature: exclamation_mark_count  |  0.0045\n",
      "feature: fight  |  0.00397\n",
      "feature: believ  |  0.00394\n",
      "feature: mad  |  0.00383\n",
      "feature: man  |  0.00376\n",
      "feature: alarm  |  0.00351\n",
      "feature: question_mark_count  |  0.00348\n",
      "feature: fak  |  0.00345\n",
      "feature: hoax  |  0.00345\n",
      "feature: left  |  0.00339\n",
      "feature: say  |  0.00326\n"
     ]
    }
   ],
   "source": [
    "# https://towardsdatascience.com/improving-random-forest-in-python-part-1-893916666cd\n",
    "rf_classifier = RandomForestClassifier()\n",
    "rf_classifier.fit(features, y_train) # fit model to all training data\n",
    "\n",
    "feature_names = vectorizer.get_feature_names() + numerical_feature_names\n",
    "importances = list(rf_classifier.feature_importances_) # higher value = more important\n",
    "feature_importances = [(feature, round(importance, 5)) for feature, importance in zip(feature_names, importances)]\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "for i in range(25): # print top 25 most important features\n",
    "    print('feature:', feature_importances[i][0],' | ',feature_importances[i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of these features make sense! There are many words related to climate change (chang, clim, warm, glob), belief (deny, scam, real, believ, fak, hoax), and politcs (lib, obam, trump). It's also intersting to note that all our numerical features were pretty important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x1a1afed668>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(feature_importances)),np.cumsum(np.array([tup[1] for tup in feature_importances])))\n",
    "plt.axhline(.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of features that capture 95% of the importance:  3933\n",
      "time: 194.70488381385803\n",
      "(0.8944566725436985, 0.8950586105274384, 0.8946028264713585, 0.8934377683074354)\n"
     ]
    }
   ],
   "source": [
    "n95 = len(feature_importances) - sum(np.cumsum(np.array([tup[1] for tup in feature_importances]))>.95)\n",
    "print('The number of features that capture 95% of the importance: ',n95)\n",
    "indices95 = np.argsort(-np.array(importances))[:n95]\n",
    "\n",
    "# train model on all training data\n",
    "features95 = features.tocsr()[:,indices95]\n",
    "\n",
    "# 5 fold cross validation on training data\n",
    "start = time.time()\n",
    "rf_classifier = RandomForestClassifier()\n",
    "errors = k_cross_val(rf_classifier,features95,y_train.values,k=5)\n",
    "stop = time.time()\n",
    "\n",
    "print('time:',stop-start)\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n_estimators_array = [100, 200, 400, 600, 800, 1000]\\nmax_depth_array = [200,400,600,800, None]\\nmin_samples_split_array = [2,5,10]\\nmin_samples_leaf_array = [1,2,4]\\n\\nparam = [n_estimators_array,max_depth_array,min_samples_split_array,min_samples_leaf_array]\\nparam_grid = list(itertools.product(*param))  \\nfor p in random.sample(param_grid,20):\\n    rf_classifier = RandomForestClassifier(n_estimators=p[0], max_depth=p[1], min_samples_split=p[2], min_samples_leaf=p[3])\\n    errors = k_cross_val(rf_classifier,features95,y_train.values,k=5)\\n    print(p,\" | \",errors)'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_estimators integer, optional (default=100)\n",
    "# max_depth integer or None, optional (default=None)\n",
    "# min_samples_split int, float, optional (default=2)\n",
    "# min_samples_leaf int, float, optional (default=1)\n",
    "\n",
    "n_estimators_array = [100, 200, 400, 600, 800, 1000]\n",
    "max_depth_array = [200,400,600,800, None]\n",
    "min_samples_split_array = [2,5,10]\n",
    "min_samples_leaf_array = [1,2,4]\n",
    "\n",
    "param = [n_estimators_array,max_depth_array,min_samples_split_array,min_samples_leaf_array]\n",
    "param_grid = list(itertools.product(*param))  \n",
    "for p in random.sample(param_grid,20):\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=p[0], max_depth=p[1], min_samples_split=p[2], min_samples_leaf=p[3])\n",
    "    errors = k_cross_val(rf_classifier,features95,y_train.values,k=5)\n",
    "    print(p,\" | \",errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this takes too long locally\n",
    "# will likely use the computing resources of something like AWS to run this"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
